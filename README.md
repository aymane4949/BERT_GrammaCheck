# ğŸ§  VÃ©rificateur de Grammaire BERT

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/downloads/)
[![BERT](https://img.shields.io/badge/ModÃ¨le-BERT-orange.svg)](https://huggingface.co/bert-base-uncased)
[![Streamlit](https://img.shields.io/badge/Framework-Streamlit-red.svg)](https://streamlit.io/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ“‹ Table des MatiÃ¨res
- [AperÃ§u](#aperÃ§u)
- [Objectif du Projet](#objectif-du-projet)
- [FonctionnalitÃ©s](#fonctionnalitÃ©s)
- [Structure du Projet](#structure-du-projet)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [DÃ©tails du ModÃ¨le](#dÃ©tails-du-modÃ¨le)
- [Technologies UtilisÃ©es](#technologies-utilisÃ©es)
- [RÃ©sultats](#rÃ©sultats)
- [Contribution](#contribution)
- [Licence](#licence)
- [Contact](#contact)

## ğŸ¯ AperÃ§u

**BERT_GrammaCheck** est une application intelligente basÃ©e sur le modÃ¨le **BERT** (Bidirectional Encoder Representations from Transformers) qui permet de **vÃ©rifier la grammaticalitÃ© de phrases en anglais**.

Ce projet comprend deux grandes parties :
1. Le **fine-tuning du modÃ¨le BERT** sur le jeu de donnÃ©es **CoLA (Corpus of Linguistic Acceptability)**
2. Une **application Streamlit** pour tester le modÃ¨le fine-tunÃ© de maniÃ¨re interactive

## ğŸš€ Objectif du Projet

L'objectif de ce projet est de dÃ©montrer l'utilisation du **fine-tuning** d'un modÃ¨le de langage prÃ©-entraÃ®nÃ© (BERT) pour une tÃ¢che de **classification binaire** :

> **DÃ©terminer si une phrase en anglais est grammaticalement correcte ou incorrecte.**

Le systÃ¨me utilise le dataset **CoLA** pour entraÃ®ner un classificateur binaire capable d'Ã©valuer l'acceptabilitÃ© linguistique des phrases anglaises.

## âœ¨ FonctionnalitÃ©s

- ğŸ¤– **ModÃ¨le BERT Fine-tunÃ©** : EntraÃ®nÃ© spÃ©cifiquement sur le dataset CoLA pour l'Ã©valuation grammaticale
- ğŸŒ **Interface Web Interactive** : Application Streamlit conviviale pour des tests en temps rÃ©el
- âš¡ **InfÃ©rence Rapide** : PrÃ©dictions instantanÃ©es de grammaticalitÃ© avec scores de confiance
- ğŸ“Š **Classification Binaire** : Identification prÃ©cise des phrases correctes/incorrectes
- ğŸ’¾ **ModÃ¨le PrÃ©-entraÃ®nÃ©** : ModÃ¨le fine-tunÃ© prÃªt Ã  l'emploi inclus dans le dÃ©pÃ´t
- ğŸ”„ **EntraÃ®nement Reproductible** : Notebook Jupyter complet pour l'entraÃ®nement et l'Ã©valuation
- ğŸ“ˆ **MÃ©triques de Performance** : Ã‰valuation dÃ©taillÃ©e avec accuracy, F1-score et MCC

## ğŸ“ Structure du Projet

Voici la structure dÃ©taillÃ©e du dossier :

```
ğŸ“¦ BERT_GrammaCheck/
â”‚
â”œâ”€â”€ ğŸ“ model_save/                          # ModÃ¨le BERT fine-tunÃ© et tokenizer sauvegardÃ©s
â”‚   â”œâ”€â”€ config.json                         # Configuration du modÃ¨le
â”‚   â”œâ”€â”€ model.safetensors                   # Poids du modÃ¨le
â”‚   â”œâ”€â”€ special_tokens_map.json             # Mapping des tokens spÃ©ciaux
â”‚   â”œâ”€â”€ tokenizer_config.json               # Configuration du tokenizer
â”‚   â””â”€â”€ vocab.txt                           # Fichier vocabulaire
â”‚
â”œâ”€â”€ ğŸ“ notebook_model/
â”‚   â””â”€â”€ bert_cola_fine_tuning.ipynb         # Notebook de fine-tuning du modÃ¨le BERT
â”‚
â”œâ”€â”€ ğŸ“ venv/                                # Environnement virtuel (non suivi par Git)
â”‚
â”œâ”€â”€ ğŸ“„ app.py                               # Application Streamlit pour tester le modÃ¨le
â”œâ”€â”€ ğŸ“„ requirements.txt                     # DÃ©pendances Python nÃ©cessaires
â”œâ”€â”€ ğŸ“„ .gitignore                           # Fichiers et dossiers Ã  ignorer par Git
â””â”€â”€ ğŸ“„ README.md                            # Documentation complÃ¨te du projet
```

## ğŸš€ Installation

### PrÃ©requis

- Python 3.8 ou supÃ©rieur
- pip (gestionnaire de paquets Python)
- Git
- Environnement virtuel (recommandÃ©)

### Instructions d'Installation

1. **Cloner le dÃ©pÃ´t**
   ```bash
   git clone https://github.com/Aymanezwikat/BERT_GrammaCheck.git
   cd BERT_GrammaCheck
   ```

2. **CrÃ©er un environnement virtuel**
   ```bash
   # Windows
   python -m venv venv
   venv\Scripts\activate
   
   # Linux/MacOS
   python3 -m venv venv
   source venv/bin/activate
   ```

3. **Installer les dÃ©pendances**
   ```bash
   pip install -r requirements.txt
   ```

## ğŸ’» Utilisation

### Partie 1 : Fine-tuning du ModÃ¨le BERT

Le notebook `bert_cola_fine_tuning.ipynb` contient le pipeline complet :

1. **Chargement du dataset CoLA**
2. **PrÃ©paration et prÃ©traitement des donnÃ©es**
3. **Fine-tuning du modÃ¨le BERT**
4. **Ã‰valuation des performances**
5. **Sauvegarde du modÃ¨le** dans `model_save/`

Pour exÃ©cuter le notebook :

```bash
jupyter notebook notebook_model/bert_cola_fine_tuning.ipynb
```

Le modÃ¨le final classe une phrase :
- âœ… **Correcte grammaticalement**
- âŒ **Incorrecte grammaticalement**

### Partie 2 : Application Streamlit

L'application `app.py` permet de tester le modÃ¨le via une interface web interactive.

**Lancer l'application :**

```bash
streamlit run app.py
```

L'application s'ouvrira automatiquement dans votre navigateur par dÃ©faut Ã  l'adresse `http://localhost:8501`

**Utilisation de l'interface :**

1. Saisissez une phrase en anglais dans le champ de texte
2. Cliquez sur le bouton de vÃ©rification
3. Consultez le rÃ©sultat :
   - âœ… **Grammaticalement Correcte** : La phrase est bien formÃ©e
   - âŒ **Grammaticalement Incorrecte** : La phrase contient des erreurs grammaticales

## ğŸ”¬ DÃ©tails du ModÃ¨le

### Architecture

- **ModÃ¨le de Base** : `bert-base-uncased`
- **TÃ¢che** : Classification Binaire de SÃ©quences
- **Dataset** : CoLA (Corpus of Linguistic Acceptability)
- **Framework** : Hugging Face Transformers + PyTorch

### Pipeline d'EntraÃ®nement

1. **Chargement des DonnÃ©es** : Dataset CoLA avec labels de grammaticalitÃ© (0/1)
2. **Tokenisation** : Utilisation du tokenizer BERT avec padding et troncature
3. **Fine-tuning** : Ajout d'une tÃªte de classification binaire sur BERT prÃ©-entraÃ®nÃ©
4. **Optimisation** : EntraÃ®nement avec AdamW et learning rate scheduling
5. **Ã‰valuation** : Calcul des mÃ©triques sur l'ensemble de test
6. **Sauvegarde** : Export du modÃ¨le et du tokenizer

### MÃ©triques de Performance

Le modÃ¨le est Ã©valuÃ© selon des mÃ©triques NLP standard :
- **Accuracy** : Exactitude globale des prÃ©dictions
- **F1-Score** : Moyenne harmonique de la prÃ©cision et du recall
- **Matthews Correlation Coefficient (MCC)** : MÃ©trique de qualitÃ© pour classification binaire

## ğŸ› ï¸ Technologies UtilisÃ©es

| Technologie | Version | Utilisation |
|------------|---------|-------------|
| **Python** | 3.8+ | Langage de programmation principal |
| **PyTorch** | Latest | Framework de deep learning |
| **Transformers** | Hugging Face | ImplÃ©mentation du modÃ¨le BERT |
| **Streamlit** | Latest | Framework d'application web |
| **Pandas** | Latest | Manipulation de donnÃ©es |
| **NumPy** | Latest | Calculs numÃ©riques |
| **Jupyter** | Latest | DÃ©veloppement interactif |
| **Datasets** | Hugging Face | Chargement du dataset CoLA |

## ğŸ“Š RÃ©sultats

Le modÃ¨le BERT fine-tunÃ© atteint des performances solides sur l'ensemble de test CoLA :
- CapacitÃ© Ã  identifier les patterns grammaticaux complexes
- DÃ©tection efficace des erreurs de syntaxe
- Haute prÃ©cision dans la classification binaire

Les mÃ©triques dÃ©taillÃ©es, les courbes d'apprentissage et l'analyse complÃ¨te sont disponibles dans le notebook d'entraÃ®nement `bert_cola_fine_tuning.ipynb`.

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  soumettre une Pull Request. 

### Pour contribuer :

1. Forkez le dÃ©pÃ´t
2. CrÃ©ez votre branche de fonctionnalitÃ© (`git checkout -b feature/NouvelleFonctionnalite`)
3. Committez vos changements (`git commit -m 'Ajout d'une nouvelle fonctionnalitÃ©'`)
4. Poussez vers la branche (`git push origin feature/NouvelleFonctionnalite`)
5. Ouvrez une Pull Request

### IdÃ©es de contributions :

- Support multilingue (franÃ§ais, espagnol, etc.)
- AmÃ©lioration de l'interface Streamlit
- Ajout de nouvelles mÃ©triques d'Ã©valuation
- Optimisation des performances
- Documentation supplÃ©mentaire

## ğŸ“„ Licence

Ce projet est sous licence MIT - voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ“§ Contact

**Ayman Ezwikat**

- GitHub : [@Aymanezwikat](https://github.com/Aymanezwikat)
- Projet : [BERT_GrammaCheck](https://github.com/Aymanezwikat/BERT_GrammaCheck)

---

## ğŸ™ Remerciements

- [Hugging Face](https://huggingface.co/) pour la bibliothÃ¨que Transformers et l'Ã©cosystÃ¨me NLP
- Les crÃ©ateurs du [Dataset CoLA](https://nyu-mll.github.io/CoLA/) (Corpus of Linguistic Acceptability)
- Les auteurs du [Paper BERT](https://arxiv.org/abs/1810.04805) : Devlin et al. (2018)
- La communautÃ© Streamlit pour le framework d'applications web

---

## ğŸ“š Ressources SupplÃ©mentaires

- [Documentation BERT](https://huggingface.co/docs/transformers/model_doc/bert)
- [Guide de Fine-tuning](https://huggingface.co/docs/transformers/training)
- [Dataset CoLA](https://nyu-mll.github.io/CoLA/)
- [Documentation Streamlit](https://docs.streamlit.io/)

---

<div align="center">
  <sub>DÃ©veloppÃ© avec â¤ï¸ en utilisant BERT et Streamlit | 2025</sub>
</div>