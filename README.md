```markdown
# ğŸ§  VÃ©rificateur Grammatical avec BERT (Fine-tuning sur CoLA)

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![BERT](https://img.shields.io/badge/ModÃ¨le-BERT-orange.svg)](https://huggingface.co/bert-base-uncased)
[![Streamlit](https://img.shields.io/badge/Framework-Streamlit-red.svg)](https://streamlit.io/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸ“˜ Table des MatiÃ¨res
- [AperÃ§u](#aperÃ§u)
- [Objectif du Projet](#objectif-du-projet)
- [FonctionnalitÃ©s](#fonctionnalitÃ©s)
- [Structure du Projet](#structure-du-projet)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [DÃ©tails du ModÃ¨le](#dÃ©tails-du-modÃ¨le)
- [RÃ©sultats](#rÃ©sultats)
- [Technologies UtilisÃ©es](#technologies-utilisÃ©es)
- [Contribution](#contribution)
- [Licence](#licence)
- [Contact](#contact)
- [Remerciements](#remerciements)

---

## ğŸ¯ AperÃ§u

**BERT Grammar Checker** est une application d'intelligence artificielle basÃ©e sur **BERT (Bidirectional Encoder Representations from Transformers)**, fine-tunÃ©e sur le dataset **CoLA (Corpus of Linguistic Acceptability)**.
Elle permet de **dÃ©terminer automatiquement si une phrase en anglais est grammaticalement correcte ou non**.

Ce projet se compose de deux volets principaux :
1. **Fine-tuning du modÃ¨le BERT** sur le dataset CoLA pour la classification binaire.
2. **Application Streamlit** permettant de tester le modÃ¨le via une interface intuitive et interactive.

---

## ğŸš€ Objectif du Projet

Ce projet a pour but de dÃ©montrer l'efficacitÃ© du **fine-tuning** d'un modÃ¨le de langage prÃ©-entraÃ®nÃ© pour une tÃ¢che NLP spÃ©cifique :
> ğŸ§© **La dÃ©tection de la grammaticalitÃ© des phrases anglaises.**

GrÃ¢ce au fine-tuning sur le dataset **CoLA**, le modÃ¨le apprend Ã  distinguer :
- âœ… les phrases **grammaticalement correctes**
- âŒ les phrases **grammaticalement incorrectes**

---

## âœ¨ FonctionnalitÃ©s

- ğŸ¤– **Fine-tuning de BERT** sur CoLA pour la classification binaire
- âš¡ **Analyse instantanÃ©e** des phrases anglaises
- ğŸŒ **Interface web Streamlit** simple et Ã©lÃ©gante
- ğŸ“Š **RÃ©sultats clairs** avec indicateurs visuels (âœ… / âŒ)
- ğŸ’¾ **ModÃ¨le fine-tunÃ© prÃªt Ã  l'emploi**
- ğŸ§  **Pipeline complet reproductible** (notebook inclus)

---

## ğŸ“ Structure du Projet

```bash
ğŸ“¦ BERT_GrammaCheck/
â”‚
â”œâ”€â”€ ğŸ“ bert_cola_finetuned/      # ModÃ¨le BERT fine-tunÃ© et tokenizer sauvegardÃ©s
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ model.safetensors
â”‚   â”œâ”€â”€ tokenizer_config.json
â”‚   â”œâ”€â”€ vocab.txt
â”‚   â””â”€â”€ special_tokens_map.json
â”‚
â”œâ”€â”€ ğŸ“ notebook_model/
â”‚   â””â”€â”€ bert_cola_fine_tuning_explained.ipynb   # Notebook complet de fine-tuning
â”‚
â”œâ”€â”€ ğŸ“„ app.py                    # Application Streamlit (interface utilisateur)
â”œâ”€â”€ ğŸ“„ requirements.txt          # Liste des dÃ©pendances
â”œâ”€â”€ ğŸ“„ .gitignore
â””â”€â”€ ğŸ“„ README.md                 # Documentation du projet
```

---

## âš™ï¸ Installation

### PrÃ©requis

- Python 3.8+
- pip
- Git
- Jupyter Notebook (pour exÃ©cuter le notebook)
- Navigateur web (pour Streamlit)

### Ã‰tapes d'installation

1. **Cloner le dÃ©pÃ´t**

   ```bash
   git clone https://github.com/Aymanezwikat/BERT_GrammaCheck.git
   cd BERT_GrammaCheck
   ```

2. **CrÃ©er un environnement virtuel**

   ```bash
   python -m venv venv
   source venv/bin/activate       # Linux / Mac
   venv\Scripts\activate          # Windows
   ```

3. **Installer les dÃ©pendances**

   ```bash
   pip install -r requirements.txt
   ```

---

## ğŸ’» Utilisation

### ğŸ”¹ Ã‰tape 1 : EntraÃ®nement du modÃ¨le (Fine-tuning)

Ouvre et exÃ©cute le notebook :

```bash
jupyter notebook notebook_model/bert_cola_fine_tuning_explained.ipynb
```

Le notebook contient :

1. Chargement du dataset **CoLA**
2. PrÃ©traitement et tokenisation
3. Fine-tuning de BERT
4. Ã‰valuation des performances
5. Sauvegarde du modÃ¨le dans `bert_cola_finetuned/`

---

### ğŸ”¹ Ã‰tape 2 : Lancement de l'application Streamlit

Une fois le modÃ¨le entraÃ®nÃ© et sauvegardÃ© (ou si vous utilisez le modÃ¨le dÃ©jÃ  fourni dans `bert_cola_finetuned/`) :

```bash
streamlit run app.py
```

Puis ouvre le lien :
ğŸ‘‰ `http://localhost:8501`

**Interface utilisateur :**

- Saisis une phrase en anglais
- Clique sur **Analyser**
- Le rÃ©sultat s'affichera automatiquement :
  - âœ… *Phrase grammaticalement correcte*
  - âŒ *Phrase incorrecte grammaticalement*

---

## ğŸ”¬ DÃ©tails du ModÃ¨le

| Ã‰lÃ©ment | DÃ©tail |
|----------|--------|
| **Architecture** | BERT-base-uncased |
| **Type de tÃ¢che** | Classification binaire |
| **Dataset** | CoLA (Corpus of Linguistic Acceptability) |
| **Frameworks** | PyTorch & Hugging Face Transformers |
| **Optimiseur** | AdamW |
| **MÃ©triques** | Accuracy, F1-Score, MCC |

---

## ğŸ“Š RÃ©sultats

Le modÃ¨le fine-tunÃ© atteint :

- **Haute prÃ©cision** sur les phrases grammaticalement correctes
- **Excellente gÃ©nÃ©ralisation** sur les phrases non vues
- **MCC Ã©levÃ©**, indiquant une performance robuste mÃªme sur donnÃ©es dÃ©sÃ©quilibrÃ©es

Les rÃ©sultats dÃ©taillÃ©s et les courbes d'apprentissage sont visibles dans le notebook d'entraÃ®nement.

---

## ğŸ§° Technologies UtilisÃ©es

| Technologie | RÃ´le |
|--------------|------|
| **Python 3.8+** | Langage principal |
| **PyTorch** | Framework d'apprentissage profond |
| **Transformers (Hugging Face)** | ImplÃ©mentation BERT |
| **Streamlit** | Interface utilisateur web |
| **Pandas / NumPy** | Manipulation de donnÃ©es |
| **Jupyter Notebook** | Environnement interactif |
| **Datasets (Hugging Face)** | Chargement de CoLA |

---

## ğŸ¤ Contribution

Les contributions sont encouragÃ©es !
Pour proposer une amÃ©lioration :

1. Fork le dÃ©pÃ´t
2. CrÃ©e une nouvelle branche (`feature/ta_fonctionnalite`)
3. Commit et push tes modifications
4. Ouvre une Pull Request ğŸ¯

**IdÃ©es de contributions possibles :**

- Support pour d'autres langues
- AmÃ©lioration de l'UI Streamlit
- Visualisation des scores de confiance
- Optimisation de la vitesse d'infÃ©rence

---

## ğŸ“œ Licence

Ce projet est distribuÃ© sous la licence **MIT**.
Consulte le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

---

## ğŸ“§ Contact

ğŸ‘¤ **Ayman Ezwikat**  
ğŸ”— GitHub : [@Aymanezwikat](https://github.com/Aymanezwikat)  
ğŸ’¡ Projet : [BERT_GrammaCheck](https://github.com/Aymanezwikat/BERT_GrammaCheck)

---

## ğŸ™ Remerciements

- [Hugging Face](https://huggingface.co/) â€“ pour la bibliothÃ¨que Transformers
- [Dataset CoLA](https://nyu-mll.github.io/CoLA/) â€“ corpus linguistique d'acceptabilitÃ©
- [Streamlit](https://streamlit.io/) â€“ framework web interactif
- [Devlin et al., 2018](https://arxiv.org/abs/1810.04805) â€“ auteurs de BERT

---

<div align="center">
<sub>ğŸš€ DÃ©veloppÃ© avec â¤ï¸ par Ayman Ezwikat â€” 2025</sub>
</div>
```